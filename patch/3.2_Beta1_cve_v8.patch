diff --git a/v8/src/builtins/finalization-registry.tq b/v8/src/builtins/finalization-registry.tq
index 389b9a5ce0..84499e19e1 100644
--- a/v8/src/builtins/finalization-registry.tq
+++ b/v8/src/builtins/finalization-registry.tq
@@ -143,22 +143,21 @@ FinalizationRegistryRegister(
     ThrowTypeError(
         MessageTemplate::kWeakRefsRegisterTargetAndHoldingsMustNotBeSame);
   }
+  const unregisterToken = arguments[2];
   // 5. If Type(unregisterToken) is not Object,
   //   a. If unregisterToken is not undefined, throw a TypeError exception.
   //   b. Set unregisterToken to empty.
-  const unregisterTokenRaw = arguments[2];
-  let unregisterToken: JSReceiver|Undefined;
-  typeswitch (unregisterTokenRaw) {
+  let hasUnregisterToken: bool = false;
+  typeswitch (unregisterToken) {
     case (Undefined): {
-      unregisterToken = Undefined;
     }
-    case (unregisterTokenObj: JSReceiver): {
-      unregisterToken = unregisterTokenObj;
+    case (JSReceiver): {
+      hasUnregisterToken = true;
     }
     case (JSAny): deferred {
       ThrowTypeError(
           MessageTemplate::kWeakRefsUnregisterTokenMustBeObject,
-          unregisterTokenRaw);
+          unregisterToken);
     }
   }
   // 6. Let cell be the Record { [[WeakRefTarget]] : target, [[HeldValue]]:
@@ -179,7 +178,7 @@ FinalizationRegistryRegister(
   };
   // 7. Append cell to finalizationRegistry.[[Cells]].
   PushCell(finalizationRegistry, cell);
-  if (unregisterToken != Undefined) {
+  if (hasUnregisterToken) {
     // If an unregister token is provided, a runtime call is needed to
     // do some OrderedHashTable operations and register the mapping.
     // See v8:10705.
diff --git a/v8/src/compiler/backend/instruction-selector.cc b/v8/src/compiler/backend/instruction-selector.cc
index 0abf01e4d6..4c40835634 100644
--- a/v8/src/compiler/backend/instruction-selector.cc
+++ b/v8/src/compiler/backend/instruction-selector.cc
@@ -274,7 +274,7 @@ Instruction* InstructionSelector::Emit(Instruction* instr) {
 
 bool InstructionSelector::CanCover(Node* user, Node* node) const {
   // 1. Both {user} and {node} must be in the same basic block.
-  if (schedule()->block(node) != current_block_) {
+  if (schedule()->block(node) != schedule()->block(user)) {
     return false;
   }
   // 2. Pure {node}s must be owned by the {user}.
@@ -282,7 +282,7 @@ bool InstructionSelector::CanCover(Node* user, Node* node) const {
     return node->OwnedBy(user);
   }
   // 3. Impure {node}s must match the effect level of {user}.
-  if (GetEffectLevel(node) != current_effect_level_) {
+  if (GetEffectLevel(node) != GetEffectLevel(user)) {
     return false;
   }
   // 4. Only {node} must have value edges pointing to {user}.
@@ -294,6 +294,21 @@ bool InstructionSelector::CanCover(Node* user, Node* node) const {
   return true;
 }
 
+bool InstructionSelector::CanCoverTransitively(Node* user, Node* node,
+                                               Node* node_input) const {
+  if (CanCover(user, node) && CanCover(node, node_input)) {
+    // If {node} is pure, transitivity might not hold.
+    if (node->op()->HasProperty(Operator::kPure)) {
+      // If {node_input} is pure, the effect levels do not matter.
+      if (node_input->op()->HasProperty(Operator::kPure)) return true;
+      // Otherwise, {user} and {node_input} must have the same effect level.
+      return GetEffectLevel(user) == GetEffectLevel(node_input);
+    }
+    return true;
+  }
+  return false;
+}
+
 bool InstructionSelector::IsOnlyUserOfNodeInSameBlock(Node* user,
                                                       Node* node) const {
   BasicBlock* bb_user = schedule()->block(user);
@@ -1197,7 +1212,6 @@ void InstructionSelector::VisitBlock(BasicBlock* block) {
   int effect_level = 0;
   for (Node* const node : *block) {
     SetEffectLevel(node, effect_level);
-    current_effect_level_ = effect_level;
     if (node->opcode() == IrOpcode::kStore ||
         node->opcode() == IrOpcode::kUnalignedStore ||
         node->opcode() == IrOpcode::kCall ||
@@ -1217,7 +1231,6 @@ void InstructionSelector::VisitBlock(BasicBlock* block) {
   // control input should be on the same effect level as the last node.
   if (block->control_input() != nullptr) {
     SetEffectLevel(block->control_input(), effect_level);
-    current_effect_level_ = effect_level;
   }
 
   auto FinishEmittedInstructions = [&](Node* node, int instruction_start) {
diff --git a/v8/src/compiler/backend/instruction-selector.h b/v8/src/compiler/backend/instruction-selector.h
index 51aafc36b5..c7bc99005d 100644
--- a/v8/src/compiler/backend/instruction-selector.h
+++ b/v8/src/compiler/backend/instruction-selector.h
@@ -417,12 +417,12 @@ class V8_EXPORT_PRIVATE InstructionSelector final {
   // Used in pattern matching during code generation.
   // Check if {node} can be covered while generating code for the current
   // instruction. A node can be covered if the {user} of the node has the only
-  // edge, the two are in the same basic block, and there are no side-effects
-  // in-between. The last check is crucial for soundness.
-  // For pure nodes, CanCover(a,b) is checked to avoid duplicated execution:
-  // If this is not the case, code for b must still be generated for other
-  // users, and fusing is unlikely to improve performance.
+  // edge and the two are in the same basic block.
   bool CanCover(Node* user, Node* node) const;
+  // CanCover is not transitive.  The counter example are Nodes A,B,C such that
+  // CanCover(A, B) and CanCover(B,C) and B is pure: The the effect level of A
+  // and B might differ. CanCoverTransitively does the additional checks.
+  bool CanCoverTransitively(Node* user, Node* node, Node* node_input) const;
 
   // Used in pattern matching during code generation.
   // This function checks that {node} and {user} are in the same basic block,
@@ -741,7 +741,6 @@ class V8_EXPORT_PRIVATE InstructionSelector final {
   BoolVector defined_;
   BoolVector used_;
   IntVector effect_level_;
-  int current_effect_level_;
   IntVector virtual_registers_;
   IntVector virtual_register_rename_;
   InstructionScheduler* scheduler_;
diff --git a/v8/src/compiler/backend/mips64/instruction-selector-mips64.cc b/v8/src/compiler/backend/mips64/instruction-selector-mips64.cc
index d43a8a56e0..1fa6ce8f3d 100644
--- a/v8/src/compiler/backend/mips64/instruction-selector-mips64.cc
+++ b/v8/src/compiler/backend/mips64/instruction-selector-mips64.cc
@@ -1523,7 +1523,7 @@ void InstructionSelector::VisitTruncateInt64ToInt32(Node* node) {
   if (CanCover(node, value)) {
     switch (value->opcode()) {
       case IrOpcode::kWord64Sar: {
-        if (CanCover(value, value->InputAt(0)) &&
+        if (CanCoverTransitively(node, value, value->InputAt(0)) &&
             TryEmitExtendingLoad(this, value, node)) {
           return;
         } else {
diff --git a/v8/src/compiler/backend/riscv64/instruction-selector-riscv64.cc b/v8/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
index 7d2e5e7853..1d6b506685 100644
--- a/v8/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
+++ b/v8/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
@@ -1277,7 +1277,7 @@ void InstructionSelector::VisitTruncateInt64ToInt32(Node* node) {
   if (CanCover(node, value)) {
     switch (value->opcode()) {
       case IrOpcode::kWord64Sar: {
-        if (CanCover(value, value->InputAt(0)) &&
+        if (CanCoverTransitively(node, value, value->InputAt(0)) &&
             TryEmitExtendingLoad(this, value, node)) {
           return;
         } else {
diff --git a/v8/src/compiler/backend/x64/instruction-selector-x64.cc b/v8/src/compiler/backend/x64/instruction-selector-x64.cc
index ca33549e3a..3f005475b8 100644
--- a/v8/src/compiler/backend/x64/instruction-selector-x64.cc
+++ b/v8/src/compiler/backend/x64/instruction-selector-x64.cc
@@ -1685,7 +1685,7 @@ void InstructionSelector::VisitTruncateInt64ToInt32(Node* node) {
       case IrOpcode::kWord64Shr: {
         Int64BinopMatcher m(value);
         if (m.right().Is(32)) {
-          if (CanCover(value, value->InputAt(0)) &&
+          if (CanCoverTransitively(node, value, value->InputAt(0)) &&
               TryMatchLoadWord64AndShiftRight(this, value, kX64Movl)) {
             return EmitIdentity(node);
           }
diff --git a/v8/src/heap/mark-compact.cc b/v8/src/heap/mark-compact.cc
index 9e4f36d35c..37cd937710 100644
--- a/v8/src/heap/mark-compact.cc
+++ b/v8/src/heap/mark-compact.cc
@@ -2557,19 +2557,28 @@ void MarkCompactCollector::ClearJSWeakRefs() {
       RecordSlot(weak_cell, slot, HeapObject::cast(*slot));
     }
 
-    HeapObject unregister_token = weak_cell.unregister_token();
+    HeapObject unregister_token =
+        HeapObject::cast(weak_cell.unregister_token());
     if (!non_atomic_marking_state()->IsBlackOrGrey(unregister_token)) {
       // The unregister token is dead. Remove any corresponding entries in the
       // key map. Multiple WeakCell with the same token will have all their
       // unregister_token field set to undefined when processing the first
       // WeakCell. Like above, we're modifying pointers during GC, so record the
       // slots.
+      HeapObject undefined = ReadOnlyRoots(isolate()).undefined_value();
       JSFinalizationRegistry finalization_registry =
           JSFinalizationRegistry::cast(weak_cell.finalization_registry());
       finalization_registry.RemoveUnregisterToken(
           JSReceiver::cast(unregister_token), isolate(),
-          JSFinalizationRegistry::kKeepMatchedCellsInRegistry,
+          [undefined](WeakCell matched_cell) {
+            matched_cell.set_unregister_token(undefined);
+          },
           gc_notify_updated_slot);
+      // The following is necessary because in the case that weak_cell has
+      // already been popped and removed from the FinalizationRegistry, the call
+      // to JSFinalizationRegistry::RemoveUnregisterToken above will not find
+      // weak_cell itself to clear its unregister token.
+      weak_cell.set_unregister_token(undefined);
     } else {
       // The unregister_token is alive.
       ObjectSlot slot = weak_cell.RawField(WeakCell::kUnregisterTokenOffset);
diff --git a/v8/src/heap/marking-visitor-inl.h b/v8/src/heap/marking-visitor-inl.h
index 557d6248fc..55c37e535b 100644
--- a/v8/src/heap/marking-visitor-inl.h
+++ b/v8/src/heap/marking-visitor-inl.h
@@ -326,7 +326,7 @@ int MarkingVisitorBase<ConcreteVisitor, MarkingState>::VisitWeakCell(
   this->VisitMapPointer(weak_cell);
   WeakCell::BodyDescriptor::IterateBody(map, weak_cell, size, this);
   HeapObject target = weak_cell.relaxed_target();
-  HeapObject unregister_token = weak_cell.relaxed_unregister_token();
+  HeapObject unregister_token = HeapObject::cast(weak_cell.unregister_token());
   concrete_visitor()->SynchronizePageAccess(target);
   concrete_visitor()->SynchronizePageAccess(unregister_token);
   if (concrete_visitor()->marking_state()->IsBlackOrGrey(target) &&
diff --git a/v8/src/objects/js-weak-refs-inl.h b/v8/src/objects/js-weak-refs-inl.h
index 0e39b00d13..aa51ee18c8 100644
--- a/v8/src/objects/js-weak-refs-inl.h
+++ b/v8/src/objects/js-weak-refs-inl.h
@@ -71,14 +71,16 @@ bool JSFinalizationRegistry::Unregister(
   // key. Each WeakCell will be in the "active_cells" or "cleared_cells" list of
   // its FinalizationRegistry; remove it from there.
   return finalization_registry->RemoveUnregisterToken(
-      *unregister_token, isolate, kRemoveMatchedCellsFromRegistry,
+      *unregister_token, isolate,
+      [isolate](WeakCell matched_cell) {
+        matched_cell.RemoveFromFinalizationRegistryCells(isolate);
+      },
       [](HeapObject, ObjectSlot, Object) {});
 }
 
-template <typename GCNotifyUpdatedSlotCallback>
+template <typename MatchCallback, typename GCNotifyUpdatedSlotCallback>
 bool JSFinalizationRegistry::RemoveUnregisterToken(
-    JSReceiver unregister_token, Isolate* isolate,
-    RemoveUnregisterTokenMode removal_mode,
+    JSReceiver unregister_token, Isolate* isolate, MatchCallback match_callback,
     GCNotifyUpdatedSlotCallback gc_notify_updated_slot) {
   // This method is called from both FinalizationRegistry#unregister and for
   // removing weakly-held dead unregister tokens. The latter is during GC so
@@ -116,16 +118,7 @@ bool JSFinalizationRegistry::RemoveUnregisterToken(
     value = weak_cell.key_list_next();
     if (weak_cell.unregister_token() == unregister_token) {
       // weak_cell has the same unregister token; remove it from the key list.
-      switch (removal_mode) {
-        case kRemoveMatchedCellsFromRegistry:
-          weak_cell.RemoveFromFinalizationRegistryCells(isolate);
-          break;
-        case kKeepMatchedCellsInRegistry:
-          // Do nothing.
-          break;
-      }
-      // Clear unregister token-related fields.
-      weak_cell.set_unregister_token(undefined);
+      match_callback(weak_cell);
       weak_cell.set_key_list_prev(undefined);
       weak_cell.set_key_list_next(undefined);
       was_present = true;
@@ -170,10 +163,6 @@ HeapObject WeakCell::relaxed_target() const {
   return TaggedField<HeapObject>::Relaxed_Load(*this, kTargetOffset);
 }
 
-HeapObject WeakCell::relaxed_unregister_token() const {
-  return TaggedField<HeapObject>::Relaxed_Load(*this, kUnregisterTokenOffset);
-}
-
 template <typename GCNotifyUpdatedSlotCallback>
 void WeakCell::Nullify(Isolate* isolate,
                        GCNotifyUpdatedSlotCallback gc_notify_updated_slot) {
diff --git a/v8/src/objects/js-weak-refs.h b/v8/src/objects/js-weak-refs.h
index 88361ad1c0..300673381a 100644
--- a/v8/src/objects/js-weak-refs.h
+++ b/v8/src/objects/js-weak-refs.h
@@ -53,14 +53,10 @@ class JSFinalizationRegistry : public JSObject {
   // it modifies slots in key_map and WeakCells and the normal write barrier is
   // disabled during GC, we need to tell the GC about the modified slots via the
   // gc_notify_updated_slot function.
-  enum RemoveUnregisterTokenMode {
-    kRemoveMatchedCellsFromRegistry,
-    kKeepMatchedCellsInRegistry
-  };
-  template <typename GCNotifyUpdatedSlotCallback>
+  template <typename MatchCallback, typename GCNotifyUpdatedSlotCallback>
   inline bool RemoveUnregisterToken(
       JSReceiver unregister_token, Isolate* isolate,
-      RemoveUnregisterTokenMode removal_mode,
+      MatchCallback match_callback,
       GCNotifyUpdatedSlotCallback gc_notify_updated_slot);
 
   // Returns true if the cleared_cells list is non-empty.
@@ -97,9 +93,6 @@ class WeakCell : public TorqueGeneratedWeakCell<WeakCell, HeapObject> {
   // Provide relaxed load access to target field.
   inline HeapObject relaxed_target() const;
 
-  // Provide relaxed load access to the unregister token field.
-  inline HeapObject relaxed_unregister_token() const;
-
   // Nullify is called during GC and it modifies the pointers in WeakCell and
   // JSFinalizationRegistry. Thus we need to tell the GC about the modified
   // slots via the gc_notify_updated_slot function. The normal write barrier is
diff --git a/v8/src/objects/js-weak-refs.tq b/v8/src/objects/js-weak-refs.tq
index 3447e31b71..9008f64290 100644
--- a/v8/src/objects/js-weak-refs.tq
+++ b/v8/src/objects/js-weak-refs.tq
@@ -22,7 +22,7 @@ extern class JSFinalizationRegistry extends JSObject {
 extern class WeakCell extends HeapObject {
   finalization_registry: Undefined|JSFinalizationRegistry;
   target: Undefined|JSReceiver;
-  unregister_token: Undefined|JSReceiver;
+  unregister_token: JSAny;
   holdings: JSAny;
 
   // For storing doubly linked lists of WeakCells in JSFinalizationRegistry's
diff --git a/v8/src/objects/objects.cc b/v8/src/objects/objects.cc
index 0c1cc482de..fa3f9fc82d 100644
--- a/v8/src/objects/objects.cc
+++ b/v8/src/objects/objects.cc
@@ -6740,7 +6740,6 @@ void JSFinalizationRegistry::RemoveCellFromUnregisterTokenMap(
       JSFinalizationRegistry::cast(Object(raw_finalization_registry));
   WeakCell weak_cell = WeakCell::cast(Object(raw_weak_cell));
   DCHECK(!weak_cell.unregister_token().IsUndefined(isolate));
-  HeapObject undefined = ReadOnlyRoots(isolate).undefined_value();
 
   // Remove weak_cell from the linked list of other WeakCells with the same
   // unregister token and remove its unregister token from key_map if necessary
@@ -6749,7 +6748,7 @@ void JSFinalizationRegistry::RemoveCellFromUnregisterTokenMap(
   if (weak_cell.key_list_prev().IsUndefined(isolate)) {
     SimpleNumberDictionary key_map =
         SimpleNumberDictionary::cast(finalization_registry.key_map());
-    HeapObject unregister_token = weak_cell.unregister_token();
+    Object unregister_token = weak_cell.unregister_token();
     uint32_t key = Smi::ToInt(unregister_token.GetHash());
     InternalIndex entry = key_map.FindEntry(isolate, key);
     DCHECK(entry.is_found());
@@ -6764,7 +6763,8 @@ void JSFinalizationRegistry::RemoveCellFromUnregisterTokenMap(
       // of the key in the hash table.
       WeakCell next = WeakCell::cast(weak_cell.key_list_next());
       DCHECK_EQ(next.key_list_prev(), weak_cell);
-      next.set_key_list_prev(undefined);
+      next.set_key_list_prev(ReadOnlyRoots(isolate).undefined_value());
+      weak_cell.set_key_list_next(ReadOnlyRoots(isolate).undefined_value());
       key_map.ValueAtPut(entry, next);
     }
   } else {
@@ -6776,12 +6776,6 @@ void JSFinalizationRegistry::RemoveCellFromUnregisterTokenMap(
       next.set_key_list_prev(weak_cell.key_list_prev());
     }
   }
-
-  // weak_cell is now removed from the unregister token map, so clear its
-  // unregister token-related fields.
-  weak_cell.set_unregister_token(undefined);
-  weak_cell.set_key_list_prev(undefined);
-  weak_cell.set_key_list_next(undefined);
 }
 
 }  // namespace internal
diff --git a/v8/test/cctest/test-js-weak-refs.cc b/v8/test/cctest/test-js-weak-refs.cc
index 52cf8a529e..1291283515 100644
--- a/v8/test/cctest/test-js-weak-refs.cc
+++ b/v8/test/cctest/test-js-weak-refs.cc
@@ -831,7 +831,7 @@ TEST(TestRemoveUnregisterToken) {
 
   Handle<JSObject> token1 = CreateKey("token1", isolate);
   Handle<JSObject> token2 = CreateKey("token2", isolate);
-  Handle<HeapObject> undefined =
+  Handle<Object> undefined =
       handle(ReadOnlyRoots(isolate).undefined_value(), isolate);
 
   Handle<WeakCell> weak_cell1a = FinalizationRegistryRegister(
@@ -861,7 +861,9 @@ TEST(TestRemoveUnregisterToken) {
 
   finalization_registry->RemoveUnregisterToken(
       JSReceiver::cast(*token2), isolate,
-      JSFinalizationRegistry::kKeepMatchedCellsInRegistry,
+      [undefined](WeakCell matched_cell) {
+        matched_cell.set_unregister_token(*undefined);
+      },
       [](HeapObject, ObjectSlot, Object) {});
 
   // Both weak_cell2a and weak_cell2b remain on the weak cell chains.
@@ -987,17 +989,15 @@ TEST(UnregisterTokenHeapVerifier) {
   v8::HandleScope outer_scope(isolate);
 
   {
-    // Make a new FinalizationRegistry and register two objects with the same
-    // unregister token that's unreachable after the IIFE returns.
+    // Make a new FinalizationRegistry and register an object with an unregister
+    // token that's unreachable after the IIFE returns.
     v8::HandleScope scope(isolate);
     CompileRun(
         "var token = {}; "
         "var registry = new FinalizationRegistry(function ()  {}); "
         "(function () { "
-        "  let o1 = {}; "
-        "  let o2 = {}; "
-        "  registry.register(o1, {}, token); "
-        "  registry.register(o2, {}, token); "
+        "  let o = {}; "
+        "  registry.register(o, {}, token); "
         "})();");
   }
 
@@ -1022,52 +1022,5 @@ TEST(UnregisterTokenHeapVerifier) {
   EmptyMessageQueues(isolate);
 }
 
-TEST(UnregisteredAndUnclearedCellHeapVerifier) {
-  if (!FLAG_incremental_marking) return;
-  ManualGCScope manual_gc_scope;
-#ifdef VERIFY_HEAP
-  FLAG_verify_heap = true;
-#endif
-
-  CcTest::InitializeVM();
-  v8::Isolate* isolate = CcTest::isolate();
-  Heap* heap = CcTest::heap();
-  v8::HandleScope outer_scope(isolate);
-
-  {
-    // Make a new FinalizationRegistry and register an object with a token.
-    v8::HandleScope scope(isolate);
-    CompileRun(
-        "var token = {}; "
-        "var registry = new FinalizationRegistry(function () {}); "
-        "registry.register({}, undefined, token);");
-  }
-
-  // Start incremental marking to activate the marking barrier.
-  heap::SimulateIncrementalMarking(heap, false);
-
-  {
-    // Make a WeakCell list with length >1, then unregister with the token to
-    // the WeakCell from the registry. The linked list manipulation keeps the
-    // unregistered WeakCell alive (i.e. not put into cleared_cells) due to the
-    // marking barrier from incremental marking. Then make the original token
-    // collectible.
-    v8::HandleScope scope(isolate);
-    CompileRun(
-        "registry.register({}); "
-        "registry.unregister(token); "
-        "token = 0;");
-  }
-
-  // Trigger GC.
-  CcTest::CollectAllGarbage();
-  CcTest::CollectAllGarbage();
-
-  // Pump message loop to run the finalizer task, then the incremental marking
-  // task. The verifier will verify that live WeakCells don't point to dead
-  // unregister tokens.
-  EmptyMessageQueues(isolate);
-}
-
 }  // namespace internal
 }  // namespace v8
